{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c52d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faf84f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt # to view digits images from array object\n",
    "from keras import  backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# import tensorflow_addons as tfa\n",
    "from keras.models import  Sequential\n",
    "from keras.layers.core import  Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from keras.layers import BatchNormalization, Conv2D , MaxPooling2D ,Activation\n",
    "# from keras.optimizers import Adam , RMSprop\n",
    "from keras.optimizers import adam_v2\n",
    "# from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a92d5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('data/train.csv')\n",
    "# test_set = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
    "\n",
    "img_col = 28\n",
    "img_row = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab53509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c1a7c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(42000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_df = train_set.drop(['label'],axis = 1)\n",
    "y_train_df = train_set['label']\n",
    "# X_test_df = test_set\n",
    "\n",
    "X_tr = np.asarray(X_train_df)/255\n",
    "y_tr = np.asarray(y_train_df)\n",
    "# X_te = np.asarray(X_test_df)/255\n",
    "print(type(X_tr))\n",
    "print(X_tr.shape)\n",
    "# print(X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc30523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ab5294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_trainplot = X_tr.reshape(42000 , img_col , img_row)\n",
    "# X_testplot = X_te.reshape(28000, img_col,img_row)\n",
    "print(X_trainplot.shape)\n",
    "# print(X_testplot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ae9d756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAim0lEQVR4nO3de3hU1bk/8O+bEEIggARiiAG5SBDBCgrF+wF/aFFqRaVH4FhEj4pWUcQr1Z56tLVy1MqvctEiWPBSbQUUsB4sULD1xkVFEZCLXBQMEBC535K8548Me8+aZpJhZs/sWXu+n+fhybvmncle5p0sd9asvbaoKoiIyD5ZfneAiIjiwwGciMhSHMCJiCzFAZyIyFIcwImILMUBnIjIUhzAiYgsxQE8RiIyXESWishhEZnid3/IOyIySERWich+EflKRC70u0+UGBHZF/GvUkTG+t0vr9XzuwMW+RbAbwD0BZDnc1/IIyJyCYD/ATAQwGIAxf72iLygqvnHYhHJB7AVwOv+9Sg5OIDHSFVnAICI9ADQyufukHceAfCoqn4Uam/xszOUFAMAbAfwT7874jVOoVDGEpFsAD0AFIrIOhHZLCLjRIR/YQXLUAAvagD3DeEATpmsCEAOgJ8CuBBANwBnAvilj30iD4lIGwC9AEz1uy/JwAGcMtnB0NexqlqmqjsAPA2gn499Im8NAfCeqm7wuyPJwAGcMpaq7gKwGUD4n9aB+zM7w12HgJ59AxzAYyYi9USkAYBsANki0kBE+CGw/f4I4A4ROVFEmgEYCeAtn/tEHhCR8wCUIICrT47hAB67X6L6T+5RAH4WijlXar9fA1gCYA2AVQA+BfCYrz0irwwFMENV9/rdkWSRAH4wS0SUEXgGTkRkKQ7gRESW4gBORGSphAZwEblURFaHrmIb5VWnyF+sa3CxtsES94eYocuQ1wC4BNVraZcAGKyqK73rHqUa6xpcrG3wJLKOuSeAdaq6HgBE5DUA/QFEfTPUl1xtgEYJHJK8cAj7cUQPS5Q062qpOuoKHGdtWdf0sRe7dqhqYeTjiQzgJQC+CWtvBnB25JNEZBiAYQDQAA1xtvRJ4JDkhUU6v7Y062qpOuoKxFBb1jU9zdNpm2p6POkfYqrqRFXtoao9cpCb7MNRirCuwcS62iWRAXwLgNZh7VbgXspBwLoGF2sbMIkM4EsAlIpIOxGpD2AQgFnedIt8xLoGF2sbMHHPgatqhYgMB/AOqjd4ekFVV3jWM/IF6xpcrG3wJLSbnqq+DeBtj/pCaSId6yo59Z04q2ljI1e5Y2fC379ecUujXfaHpkZ7Ufc/OXHHd24xch3/c2nCx0+VdKwtxY9XYhIRWYoDOBGRpTiAExFZineUIStkneDOSR/s3tbI1Z+T+Bz4ykdbG+013Z8z2lWocuKpvScZucfQLeHjE8WDZ+BERJbiAE5EZClOoZAVKsvLnbj+nPJannkcev7ACV/u84eYX7a1omndTyJKAZ6BExFZigM4EZGlOIATEVmKc+A1OHLpD4327EljnTg/q4GR6/iP64x2u0GfJ69j5KldDx9y4h65lRHZ6Oc2z955jdGujyVedosoZjwDJyKyFAdwIiJLcQqlBpsGVRntHMl24qNq/qn9VPdpRvvpy6514tz/5Z/W6SRyx8GpXaaGtXJi/j4NV5QZ7YpEOkWUAJ6BExFZigM4EZGlOIATEVmKc+A1KL3+Y6Pdb94AJ55z2htG7rKGe412g7FTnPh3Hbp43zmKW9Nph412h5zod13PghjtrhNGOHHrbz7wtmNEceIZOBGRpTiAExFZilMoMdj9WonbeMS/ftDx+/a+85z4lZOfNHJVqB/5dMcb+1sY7baT1jlx5DWbZJIf/sBotxnv/uz++fUpRu7gjoZOfNr9Xxq5yj17ktC7YOEZOBGRpTiAExFZigM4EZGlOAfusVs/GOLEpfjEx55kpnptzJsTP3TTq07cOCv6nHd5pbnEcNx9A4123rbFHvQuM2w9t7HRnnHSu06cW/J+1NfNvTjPaN857T+duMMfzbsw6WZ3OwNpVWzkKtducBtVtX9ioed1deL1A8zj9zxntRNfWWj+Lv/3S+6WGa1/7d+yUp6BExFZqs4BXEReEJHtIvJF2GMFIjJXRNaGvjZLbjfJa6xrcLG2mSOWKZQpAMYBeDHssVEA5qvqaBEZFWo/4H337FPyZuy72vlsCgJY15UPmjsOXpW/PepzVx1xd50cPOV+I3fyTKuvtpwCH2tb9Iz5s3treKETD2i0K+rrLsk7aLRXDRnvNoaYz3243J36eKTwn0au1/KfOvG+v5rvh0MXmldOLz3PvZl1nkSfYot01a3uTV56f3mbkct/fVHM3ydRdZ6Bq+o/AHwX8XB/AMf24pwK4Epvu0XJxroGF2ubOeKdAy9S1WOfImwFUORRf8hfrGtwsbYBlPCHmKqqADRaXkSGichSEVl6FIejPY3SDOsaXLXVlnW1S7zLCLeJSLGqlolIMYCoE42qOhHARABoIgVRBwRKC1bWVc/v5sRrLn/OyFUhuiHPjnTik5+wes47FjHVNtV17Tp2uBO3XHTIyK0f4H6e1O/sZVG/x4hvzzXa3ZpvcRvXbUFtej53txNnHzFzJXN3O/F3XZsYuQ8fc+fni+5Yb+T2v17rIT0V7xn4LABDQ/FQADO96Q75jHUNLtY2gGJZRvgqgA8BnCoim0XkRgCjAVwiImsBXBxqk0VY1+BibTNHnVMoqjo4SqqPx31JW993iv6XZPclPzPaJW9/5sS1/fnutyDVdXNvd0e7yBsxhJ+jfF1hLlNr9Y67pO14aiU55nKzqh6nOXHOtt1GrmL9xuP4zt5It9puO3pCWMtcRihhP/jsBebVjqUL3Hit990CALRG9Kmz8N/6guzToz6vXpZ/v+m8EpOIyFIcwImILMUBnIjIUtyNMAYfDPxdWKuBkTt0MGI+9JC5FIqS72Dbo05cFbG8uSpsdrvv+8ON3CmfLYv5GAeuOtuJi+9ZZ+ReajfJiecdNHfie+yX1ztx49c+ivl4QfL7OZc58W2DJvjYk/hlfb/faC87UuHED5a8beQeau3eBL3im83J7VdSvzsRESUNB3AiIktxCoWsk93lVKP9cp8/RHmmqeMj+4x2+Fb/WY3NqY8vn+lotJdc/LQT13ZjiIvzzN3uTvitO2Xw6Pqh5pMXL6+tu5RGdNsOoz1vXxcnvrdgtfnchuY0azLxDJyIyFIcwImILMUBnIjIUpwDr0FWg9TNYdHx29vxBKPdI9eYzY76OjlgLvHMLjrRiRtOMy+HXtN+otGuQvR57/Clg5Fz4D1z3WWNzceYS8p29XHfZ5m6/LTk0k1OrE/42JE66KltjPa9Be9GeWZq8QyciMhSHMCJiCzFAZyIyFKcA6/B+qnmGuBmWe878WE9auTyFjVKSZ/IVfbv3tzqa82Yk5x4RfvnI7LRz226jx1htIsWu/1pOflZI3dG2NT5H9v+zchdXXiVE1cl+ZJrP7WaH/YZxSAz16Gxu746WVvGBhnPwImILMUBnIjIUpxCCam86CwnHtv9pajP21tVYbRb/v/A3ww37RS/nmu0s3q55yG13ZGnoqTAyKzqNbnG5wHA+4dyjPaDDw1z4lbTlxq5vVe5753siN0QcyTbPd6RiKmfo+Z0XFDlznHvtHPD172NXGF9d3uD7MJCI1dZXp7UfgUBz8CJiCzFAZyIyFIcwImILMU58JBDBe6c50V5mXlZsy0af7DBaE/f18KJB+Sb236G35Hn9PFfRM1F2lNlbqdwuIk7t95kgbn17Mx2Y8Na5jnRUXWX0P149kgjV7p1UdTjB0qV+zMov7XESO3csduJK8u/TVmXjlul+dnGYXU/C8sV/4ZRnoETEVmKAzgRkaU4hXKc3jnQ3u8uZLzKbduN9iOfX+7EA86bEvV1v20Z+5TFZQ3NXQX7PvxMTK8rrzSXCv7o+fuduOMTHxs584/yzFD12Sqz7VM/jpd+usJoj9p6vhOPKfZvKoxn4ERElqpzABeR1iKyQERWisgKERkRerxAROaKyNrQ12bJ7y55hXUNJtY1s8RyBl4B4B5V7QzgHAC3i0hnAKMAzFfVUgDzQ22yB+saTKxrBqlzDlxVywCUheK9IrIKQAmA/gB6h542FcBCAA8kpZcpsPXqIzE9b/wTA4x2AT5MRneSLkh1bfsbd0nX/OkNjdxFefsin56w4Zt7G+13/36GE5/8jjkH3nqhu9VCKua8g1RXqttxzYGLSFsAZwJYBKAo9GYBgK0AirztGqUK6xpMrGvwxTyAi0g+gOkA7lLVPeE5VVVEOcEQkWEislRElh6FN/s4k3dY12BiXTNDTMsIRSQH1W+GV1R1RujhbSJSrKplIlIMYHtNr1XViQAmAkATKUjblVOTzpkaNffpEXexU953lVGfZ5ug1DV8adqYnw00cuNGuzvaTS+dFfP3PHXezUa7+C33St3Gb35q5NodTa9ptKDUNZ3N+VsPJx4zNI2XEYqIAJgMYJWqPh2WmgVgaCgeCmCm992jZGFdg4l1zSyxnIGfD2AIgOUisiz02IMARgP4i4jcCGATgGuS0kNKFtY1mFjXDBLLKpT3gH/ZJf+YPt52h1KFdQ0m1jWz8FL6GHx5uNiJc3dlxl1UrPXR50bzaG83vgI/jPnblOKTqDlODFP7R8LeH0PN3MF27jVS9Vcntx+8lJ6IyFIcwImILMUplJAH/vsWJ35v9DgjN7jxNicee4q50X/Bu8ntFxHZZeNVbtxxTnKPxTNwIiJLcQAnIrIUB3AiIktxDjykxXvuDVV7PnaHket5vXvpdOH75UYuOBfWE1E8qiIWlj7ee5oT/zEr4g5eVd6OGDwDJyKyFAdwIiJLcQolpGLDJic+ccImI7dxQnhrXWo6RERpSw+7W+12nP1zI7fuJ8858YSf/LuRy5u52NN+8AyciMhSHMCJiCzFAZyIyFKcAyciSsBJ883de7OvSN15Mc/AiYgsxQGciMhSnEIhIkpAo82HjPbmin0pOzbPwImILMUBnIjIUhzAiYgsJaqpu0WriJQD2ASgBYAdKTtw7TKxL21UtdCrb8a61ol19U6m9qXG2qZ0AHcOKrJUVXuk/MA1YF+8k079Z1+8k079Z19MnEIhIrIUB3AiIkv5NYBP9Om4NWFfvJNO/WdfvJNO/WdfwvgyB05ERInjFEqMRKRARN4Qkf0isklE/sPvPpF3RKRURA6JyMt+94W8E/S68lL62I0HcARAEYBuAP4qIp+p6gpfe0VeGQ9gid+dIM8Fuq4pPQMXkUtFZLWIrBORUak8duj4L4jIdhH5IuyxAhGZKyJrQ1+b1fC6RgAGAPgvVd2nqu8BmAVgSJz9aC0iC0RkpYisEJERsfYlHdla17DnDgLwPYD5HvQlMLVlXY3vlZZ1TdkALiLZqP6/4WUAOgMYLCKdU3X8kCkALo14bBSA+apaiupC1/RG7QigQlXXhD32GYAucfajAsA9qtoZwDkAbg/9LGLpS1qxvK4QkSYAHgVwt0d9CURtWdd/kZZ1TeUZeE8A61R1vaoeAfAagP4pPD5U9R8Avot4uD+AqaF4KoAra3hpPoA9EY/tBtA4zn6UqeonoXgvgFUASmLsS7qxua4A8GsAk1V1s0d9CUptWVezL2lZ11TOgZcA+CasvRnA2Sk8fjRFqloWireieo470j4ATSIeawJgb6IHF5G2AM4EsCjGvqQba+sqIt0AXIzqn7/nLK8t6xpFOtWVH2KGUVUVkZrWVa4BUE9ESlV1beixrgAS+gBTRPIBTAdwl6ruEXFvzVRLX+g41fKz7A2gLYCvQz/7fADZItJZVc9K5JisbfKxrqmdQtkCoHVYu1XoMb9tE5FiAAh93R75BFXdD2AGgEdFpJGInI/qP51eivegIpKD6jfCK6o6I9a+pCFr64rqCzFOQfWqom4AngPwVwB9EzlwQGrLukZIx7qmcgBfAqBURNqJSH0Ag1C9ksNvswAMDcVDAcyM8rzbAOShukCvAvh5vEsIpfp/25MBrFLVp+PoSzqxtq6qekBVtx77h+qpskOqWh7vQQNUW9Y1TNrWVVVT9g9AP1RPR3wF4KFUHjt0/FcBlAE4iuo5vRsBNEf1p8drAcwDUJCCflwAQAF8DmBZ6F8/P/rCurK2rKu9deWl9EREluKl9EREluIATkRkqYQGcL8vtaXkYF2Di7UNlrjnwEOX2q4BcAmqP2BYAmCwqq6M9pr6kqsN0Ciu45F3DmE/juhhqSnHutqrtroCx19b1jV97MWuHVrDPTETuZDHudQWAETk2KW2UX/RG6ARzpY+CRySvLBIa93bh3W1VB11BY6ztqxr+pin0zbV9HgiUyg1XWpbEvkkERkmIktFZOlRHE7gcJQirGtw1Vlb1tUuSf8QU1UnqmoPVe2Rg9xkH45ShHUNJtbVLokM4Ol6qS0lhnUNLtY2YBIZwNP1UltKDOsaXKxtwMT9IaaqVojIcADvAMgG8ILy9mLWY12Di7UNnoS2k1XVtwG87VFfKE2wrsHF2gYLr8QkIrIUB3AiIktxACcishQHcCIiS3EAJyKyFAdwIiJL8a70Mdg8vYsT393Z3DBo8d52Rnve6k5O3GFshfmNFi/3vnNElLF4Bk5EZCkO4EREluIATkRkKc6BH5OV7YQbHutppJad/XsnzhXzRzaw8UajvbrwXScu+LcjRq7PwjuduNPd5usqd353XN0lIv9kd3A/+zpr2jojd1fzj5z4omfuM3InPfmBp/3gGTgRkaU4gBMRWYpTKCGVvbo68arrxkdko/+YLvz4eqPdcuBGJ179ZFcjt/bqZ5149kdNjNzE/v3cvqxcU0dvKQjqtSxy4tVPFxu5xu83dOITx3v7Zzcl7sAE92bwDxcuM3IjvnXvI3ry9G+NXMTC4oTxDJyIyFIcwImILMUBnIjIUpwDD9l3356ouY8Ou/Gk7b2M3KktthvtXYcOubn7PjNyV4y+3Ik7zdpq5K59w71E/+WBfY1c1bKVUftGsctu0dxof9+n1ImbfrnbyFV9tsr743cwt11YNfJEN+41zshd0vwatxH5kQylnHTvYrSf6Tg5rJVj5BZPPNOJm6//MJnd4hk4EZGtOIATEVkqY6dQdt58rtGeffqTYa2GRm7ko7c7ceHCLUbuaEmB0Ra4V1RWhU2nAEDVFndJ0bvPmsd/4pGlTvzLW/KNXMefR/ae4vHVyI5Ge+X17tzEWUuuNXItr/T++PsipkLWnu4uKx2w7nIjl9d3g/cdoOMSPuV12kRzSq1NPXcZ4YKDDYxc4WtfOHFVkvp2DM/AiYgsxQGciMhSHMCJiCyVsXPgw++ZbrSL67nzzqULrzdy7ae4S4EiL4WVjV/Hdfzmk8zlRUsedOfUftzDXH64Nq4jEACsec7dWXJa398buX1a6cYbmnpyvOzTSo32N791l5gt6Py8kRu4vr8TH7n6qCfHDxLJqe/EOudEIzfgpE+c+M3+5udJlWu+8uT4625q6cQzW06LyLp9u/NPNxmZNnuTu3QwHM/AiYgsVecALiIviMh2Efki7LECEZkrImtDX5slt5vkNdY1uFjbzBHLFMoUAOMAvBj22CgA81V1tIiMCrUf8L573qq6oJsTX99kmZE7rO6fsC1mm8uCUmHokhuceO65E4zcLd2GObGHV2VOQUDqGi67ibnL45/7umv3utU33+5dF7k/8w4jP4IXyp8Uo73szJed+KWIG2AfuNJdZObxDT2mIAC1/e7a7k78z07PGLlJu9s78aGTTzByOXFu5rl34DlG+6kBU524KmJBYL9VA5y47UzzKm5F6tR5Bq6q/wAQ+e7qD+DYf91UAFd62y1KNtY1uFjbzBHvh5hFqloWircCKIr2RBEZBmAYADSIuECG0g7rGlwx1ZZ1tUvCH2KqqqKWvxpUdaKq9lDVHjnITfRwlCKsa3DVVlvW1S7xnoFvE5FiVS0TkWIA2+t8hQ+ym5uXuec9VubElWrOaf26/CwnbvKqN/Oh8SrJNs98dnZ1l7g1W5bUQ1tR10hZjRo58ZpnTzFy3esvdOL7t/Ywcq0ed89fjmfeMrvLqUZ7/UD3ffbZmeZc7eANlzrxvsvNRaiV36f0RtbW1fZHd70XNbdgp1uD3PdWGLl4L18/dO0uo9234e4ozwS+e6OVE5/4sX93TIr3DHwWgKGheCiAmd50h3zGugYXaxtAsSwjfBXAhwBOFZHNInIjgNEALhGRtQAuDrXJIqxrcLG2maPOKRRVHRwl1SfK42mjqn2J0Z7eYWqUZwJzxl/gxM2Ruiup/GJzXSNtucW9eXSzpjuMXJ8VVztxg36bjZxWLI/reGtuMJdQvxB2s+pOs283ch1v+9htVFUiFWyt7RmfmEsww28WPP+guUPnnvvd3205ZF65fDy+esW9+cI7XcdGZN3PADr/+Q4jc+pf3OujU1PVmvFKTCIiS3EAJyKyFAdwIiJLBXo3wg1X5EfNhd+oGACK5rl3y4nccZDSy9YR5xntzgO+dOLlb3Uyci3GuLvWVVXEX9mDV7q7Gv7ix28auds/+w8nPvWOZUZOUzTvbauqXu4c9LbD5i6COZLtxFkRiwPr7T7oNiKWC6OF2950tbmL4YH25q6PF7Zf7cRt65nLd+cfdOfAT5l20MhVlpcjHfAMnIjIUhzAiYgsFegplL6XLY2ae2Wn+Wd4xYZNye5OrURSuYeZhc45wwmn3jXGSDXMcqdGRr7W2MhVRNxYOlb1WppbhbS4273J8HVNzBtbvzjZnarTo0fiOl6mCL9RMADkPepOXT5/8nwjd1Td88teeebUx6SJO524S+OtRu7BFnOdOHIXwdpURZzP9so74B7vCXMJ6r5b3CtBK1eshl94Bk5EZCkO4EREluIATkRkqcDNge//6dlOPLpl5KWx7n/u398+y8i0gX87igGAqnsZcVnlASPXbPX+VHfHd9+91dFoP9dlkhPnirk072e/uteJm22IbxuErNPN5Yedppq3dXmipft5yuv7Whi5by90l7vhQvMGuw23unVtOcbf91g62N6rpdH+U9unwlr1EauX2s2pJRvfeeltm//NaK97uLMTbz8rx8i1UXPLBr/wDJyIyFIcwImILMUBnIjIUoGbAz+S7/4/KVei/+c1/yK9LnHuWuKuLb5i2Y1GrvCjz1PdHV+U3eOuzV9y5u+NXL2wt2rHBbcYudzW7jzzvl+a6/vzz3Uvee554tdRj315szeM9iV55qXTVWH37Cmtv83IVbaM2JchTPO5EjWXKcLXfs94+EkjV5Qd323bei65zomz5prb+xYt3uvEV079u5G7oelGo/2r7T904i39zL7U37nEiVtFTLmny+jBM3AiIktxACcislTgplBilf/6Il+Pv++ac4z22+0mOHGH5bcaucKU9Mh/Fwxydw7MFXPZVvhNqNdcNNl84UVueFCjX8qeFXG+UtsU24hvzeWAy0Z3c+JG0833Tik+AUVXuc7dhuDH4+43co/dPMWJn97wIyO3c95JTnzSE+YSzJZYFfV42vMHTnxj08hpM/M9MG2h+3vYYae/NzOPB8/AiYgsxQGciMhSHMCJiCwVuDnwJhvdJV07q8ylYM2z8pz4+yHmHOcJLyX/TvTZRe7dQW5+dEbU5+V/FbiyxGTj4GIn7v7/fh7z6+qF7Rh7wovR67j5F+YSw8+Hj3Pi2QeaGLn1/cx2o3J/PzMJisi57PFPuFsm5GKj+dyIdjSRW9ReOdXdljZyO9mR315otDv+akXYc+3DM3AiIktxACcislTg/lbPXugu6bpm1bVGbn4Xd9ripw/8zcj9/U13yVLV3r3wRNhyJgD4wR+WO/GQiLuIdJl8uxO3eSozd60LX27WIixORNWF7k1z7xgy08itOerOvYwZaS7dbFC+2JPjU/JtfqqB0b6hyTdOPP+geWPzVf9l/k7W37sENuMZOBGRpeocwEWktYgsEJGVIrJCREaEHi8Qkbkisjb0tVld34vSB+saTKxrZonlDLwCwD2q2hnAOQBuF5HOAEYBmK+qpQDmh9pkD9Y1mFjXDFLnHLiqlgEoC8V7RWQVgBIA/QH0Dj1tKoCFAB5ISi/j9P3sk8wHurjh3c3WGqn/Pde9Hjvnb9HvZh9Jcs0dzHYPcOdc//T4U0auMNv9cXd6aaSRa/+r5C9jDGdzXWuT1cCcD71u0iwnHpRfbuTOesq9k0/Lt4LxuUNQ6xpJuru/zL/p8kbU5937vLmzZ+uF5rYHNi4dDHdcH2KKSFsAZwJYBKAo9GYBgK0AiqK8ZhiAYQDQAA3j7iglD+saTKxr8MX8IaaI5AOYDuAuVd0TnlNVBcI2TDZzE1W1h6r2yEF8e/9S8rCuwcS6ZoaYzsBFJAfVb4ZXVPXYWrxtIlKsqmUiUgxge7I6Ga+TXjZ3LOtw1s1OvO5Hzxu56ZOfceLzJ95r5PK/cd/r3/c1bzh80SnmzW8nlEwIa5lnMOc+5C4VbD8ltVMmNbG1rrVZ/WRXoz0o350aKZ13k5HrONZdKljjaGapINY18mrLG1+d7cSXNTSX/Z72mvt7dsr/mFNjtk+ZRIplFYoAmAxglao+HZaaBWBoKB4KYGbkayl9sa7BxLpmlljOwM8HMATAchFZFnrsQQCjAfxFRG4EsAnANUnpISUL6xpMrGsGiWUVynsAot3Yr4+33aFUYV2DiXXNLIG7lD5c5a5dRrvT8C+deOAc8+4ff27vXlq//NZxiNX2SnNO/PGdPZx4xoSLjFzhi7w8O9lKO2+Jmit4z/xQTisqkt0d8khVU/PzpNY5O91cxHNbfJqCDqUJXkpPRGQpDuBERJYK9BRKpKr9+534wFXmFXsdHr/Ficf0ftXI/aShu4x28p5WRm7i7/ob7eaT3OWBhfB/qWCmqXdTttG+6Ax3l8Hms+y7aS1V+/rSpka7a303PuOFO41c25cz5/eOZ+BERJbiAE5EZCkO4ERElsqoOfBwlTt2Gu2ON7vtZ9HByD1by/dpznnutFKxYZPRzotok52qupqXy0/a3d6Jm65LdW/SB8/AiYgsxQGciMhSGTuFQkT2aHPNcqM9C82duFkGT2PyDJyIyFIcwImILMUBnIjIUhzAiYgsxQGciMhSHMCJiCzFAZyIyFIcwImILMUBnIjIUhzAiYgsJaqauoOJlAPYBKAFgB0pO3DtMrEvbVS10KtvxrrWiXX1Tqb2pcbapnQAdw4qslRVe9T9zORjX7yTTv1nX7yTTv1nX0ycQiEishQHcCIiS/k1gE/06bg1YV+8k079Z1+8k079Z1/C+DIHTkREieMUChGRpVI6gIvIpSKyWkTWicioVB47dPwXRGS7iHwR9liBiMwVkbWhr81S0I/WIrJARFaKyAoRGeFXX7zAuhp9CUxtWVejL2lZ15QN4CKSDWA8gMsAdAYwWEQ6p+r4IVMAXBrx2CgA81W1FMD8UDvZKgDco6qdAZwD4PbQz8KPviSEdf0Xgagt6/ov0rOuqpqSfwDOBfBOWPsXAH6RquOHHbctgC/C2qsBFIfiYgCrfejTTACXpENfWFfWlnW1p66pnEIpAfBNWHtz6DG/FalqWSjeCqAolQcXkbYAzgSwyO++xIl1jcLy2rKuUaRTXfkhZhit/t9oypbliEg+gOkA7lLVPX72Jcj8+FmytsnHuqZ2AN8CoHVYu1XoMb9tE5FiAAh93Z6Kg4pIDqrfCK+o6gw/+5Ig1jVCQGrLukZIx7qmcgBfAqBURNqJSH0AgwDMSuHxo5kFYGgoHorqua2kEhEBMBnAKlV92s++eIB1DROg2rKuYdK2rime+O8HYA2ArwA85MMHD68CKANwFNVzejcCaI7qT4/XApgHoCAF/bgA1X9qfQ5gWehfPz/6wrqytqyrvXXllZhERJbih5hERJbiAE5EZCkO4EREluIATkRkKQ7gRESW4gBORGQpDuBERJbiAE5EZKn/AzV5ETuNgxaeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_img = np.random.randint(42000,size = 6)\n",
    "fig = plt.figure()\n",
    "\n",
    "for i,idx in enumerate(rand_img,1):\n",
    "    arr1 = X_trainplot[idx]\n",
    "    ax1 = fig.add_subplot(2,3,i)\n",
    "    ax1.imshow(arr1 )\n",
    "    ax1.set_title(y_tr[idx])\n",
    "    \n",
    "# rand_img = np.random.randint(28000,size = 3)\n",
    "# for i,idx in enumerate(rand_img,4):\n",
    "#     arr1 = X_testplot[idx]\n",
    "#     ax1 = fig.add_subplot(2,3,i)\n",
    "#     ax1.imshow(arr1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6daa078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_f = X_tr.reshape(42000,img_col,img_row,1)\n",
    "# X_test_f= X_te.reshape(28000,img_col,img_row,1)\n",
    "y_train_f = to_categorical(y_tr)\n",
    "y_train_f.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb158368",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128,(2,2),padding = 'same', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128,(2,2),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64,(2,2),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10 , activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6024836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_lr = 1e-2\n",
    "# decay_steps = 150\n",
    "# alpha = 1e-5\n",
    "# beta = 1e-8\n",
    "# num_periods=4\n",
    "# lin_cos_dec1 = tf.keras.experimental.LinearCosineDecay(init_lr,\n",
    "#                                                        decay_steps,\n",
    "#                                                        num_periods=num_periods, alpha=alpha,\n",
    "#                                                        beta=beta, name='LinCosDec 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a31c24df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 577,226\n",
      "Trainable params: 574,538\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = adam_v2.Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01b03a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_f, y_train_f, test_size=0.3 , random_state = 5)\n",
    "image_gen = ImageDataGenerator(rotation_range = 25 ,shear_range = 0.25,zoom_range = [1.25,0.75],width_shift_range= 0.1,height_shift_range=0.1)\n",
    "image_gen2 = ImageDataGenerator()\n",
    "train_batches = image_gen.flow(X_train,y_train,batch_size = batch_size)\n",
    "val_batches =image_gen2.flow(X_val,y_val,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c8e2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_batches.n//train_batches.batch_size\n",
    "validation_steps = val_batches.n//val_batches.batch_size\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75,patience=3, min_lr=0.00001, mode='auto',verbose=1)\n",
    "callbacks = [PlotLossesKerasTF(), reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "385b591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "157/459 [=========>....................] - ETA: 1:33 - loss: 2.2234 - accuracy: 0.2268"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d8ed63d0a272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history=model.fit_generator(generator=train_batches, steps_per_epoch = steps_per_epoch, epochs=epochs, \n\u001b[0m\u001b[1;32m      2\u001b[0m                     validation_data=val_batches, validation_steps=validation_steps , callbacks=callbacks)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1916\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1918\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=train_batches, steps_per_epoch = steps_per_epoch, epochs=epochs, \n",
    "                    validation_data=val_batches, validation_steps=validation_steps , callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test_f, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"mysub5.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f74ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "y_true = np.argmax(y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (y_pred_classes - y_true != 0)\n",
    "print(sum(errors))\n",
    "y_pred_classes_errors = y_pred_classes[errors]\n",
    "y_pred_errors = y_pred[errors]\n",
    "y_true_errors = y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "y_pred_errors_prob = np.max(y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[:6]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, y_pred_classes_errors, y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a54ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a24c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
